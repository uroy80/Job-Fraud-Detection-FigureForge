# Job Fraud Detection System

A machine learning-powered system to detect fraudulent job postings and protect job seekers from scams.

## ğŸ¯ Project Overview

This system uses advanced machine learning techniques to identify fraudulent job postings with high accuracy. It features:

- **Binary Classifier**: Ensemble model (Random Forest + Gradient Boosting + Logistic Regression)
- **Advanced Features**: 25+ engineered features including text analysis and fraud indicators
- **F1-Score Optimized**: Specifically tuned for imbalanced datasets
- **Interactive Dashboard**: Real-time analysis with visualizations

## ğŸ“Š Core Features

### 1. Upload & Parse
- Accepts CSV files with job listing data
- Required columns: `title` (minimum)
- Optional columns: `description`, `location`, `company`, `salary_range`, etc.
- Handles missing data gracefully

### 2. Processing Engine
- **Text Cleaning**: Advanced preprocessing with fraud-specific keyword detection
- **Feature Engineering**: 25+ features including urgency indicators, contact patterns, etc.
- **ML Pipeline**: Ensemble classifier optimized for F1-score
- **Output**: Class prediction (genuine/fraudulent) + probability score

### 3. Dashboard Visualizations
- **Results Table**: Searchable/sortable table with all predictions
- **Histogram**: Distribution of fraud probabilities
- **Pie Chart**: Proportion of genuine vs fraudulent jobs
- **Top 10 Suspicious**: Highest risk job listings

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ 
- Python 3.8+
- npm or yarn

### Installation

1. **Clone and install dependencies:**
\`\`\`bash
git clone <repository-url>
cd job-fraud-detection
npm install
\`\`\`

2. **Install Python dependencies:**
\`\`\`bash
pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn
\`\`\`

3. **Prepare training data:**
   - Place your training data as `training_data.csv` in the project root
   - Required column: `fraudulent` (0 for genuine, 1 for fraudulent)
   - Recommended columns: `title`, `description`, `company_profile`, `location`, etc.

4. **Train the model:**
\`\`\`bash
python scripts/train_enhanced_model.py
\`\`\`

5. **Start the application:**
\`\`\`bash
npm run dev
\`\`\`

6. **Open your browser:**
   Navigate to `http://localhost:3000`

## ğŸ“ Project Structure

\`\`\`
job-fraud-detection/
â”œâ”€â”€ app/                          # Next.js app directory
â”‚   â”œâ”€â”€ api/                      # API routes
â”‚   â”‚   â”œâ”€â”€ predict/              # Prediction endpoint
â”‚   â”‚   â””â”€â”€ model-performance/    # Performance metrics
â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â””â”€â”€ page.tsx                 # Main page
â”œâ”€â”€ components/                   # React components
â”‚   â”œâ”€â”€ dashboard.tsx            # Main dashboard
â”‚   â”œâ”€â”€ file-upload.tsx          # File upload component
â”‚   â”œâ”€â”€ results-table.tsx        # Results table with pagination
â”‚   â”œâ”€â”€ fraud-distribution.tsx   # Histogram chart
â”‚   â”œâ”€â”€ fraud-pie-chart.tsx      # Pie chart
â”‚   â”œâ”€â”€ top-suspicious-listings.tsx # Top 10 suspicious jobs
â”‚   â””â”€â”€ model-performance-real.tsx # Real performance metrics
â”œâ”€â”€ scripts/                     # Python scripts
â”‚   â”œâ”€â”€ train_enhanced_model.py  # Enhanced model training
â”‚   â”œâ”€â”€ predict_enhanced.py      # Enhanced prediction
â”‚   â””â”€â”€ evaluate_model.py        # Model evaluation
â”œâ”€â”€ training_data.csv           # Your training dataset (place here)
â”œâ”€â”€ model_performance.pkl       # Saved performance metrics
â”œâ”€â”€ enhanced_model.pkl          # Trained model
â”œâ”€â”€ enhanced_vectorizer.pkl     # Text vectorizer
â””â”€â”€ enhanced_scaler.pkl         # Feature scaler
\`\`\`

## ğŸ”§ Usage

### 1. Training the Model (Manual Step)

**Prepare your training data** (`training_data.csv`):
\`\`\`csv
title,description,company_profile,location,fraudulent
"Software Engineer","Great opportunity...","Tech company...","New York",0
"Make Money Fast","Easy work from home...","","Remote",1
"Data Scientist","Looking for ML expert","Established analytics firm","San Francisco",0
"Earn $5000/week","Simple online work","","Work from home",1
\`\`\`

**Train the enhanced model:**
\`\`\`bash
python scripts/train_enhanced_model.py
\`\`\`

**Expected output:**
- Model files: `enhanced_model.pkl`, `enhanced_vectorizer.pkl`, `enhanced_scaler.pkl`
- Performance metrics: `model_performance.pkl`
- Visualizations: `feature_importance.png`, `confusion_matrix_enhanced.png`

### 2. Using the Dashboard

1. **Upload CSV**: Click upload area and select your job listings CSV
2. **View Results**: Navigate through the 4 core visualization tabs:
   - **Results Table**: All predictions with search/filter
   - **Histogram**: Fraud probability distribution
   - **Pie Chart**: Genuine vs fraudulent proportions
   - **Top 10 Suspicious**: Highest risk listings

### 3. CSV Format for Prediction

**Minimum required:**
\`\`\`csv
title
"Software Developer Position"
"Work from Home Opportunity"
\`\`\`

**Recommended format:**
\`\`\`csv
title,description,location,company,salary_range
"Software Developer","Join our team...","San Francisco","TechCorp","$80k-120k"
"Easy Money","Make $5000/week...","Remote","","$5000/week"
\`\`\`

## ğŸ§  Model Details

### Features Engineered (25+)
- **Text Features**: Title/description length, word count, fraud keywords
- **Fraud Indicators**: Urgency words, money mentions, contact patterns
- **Job Characteristics**: Experience requirements, education needs, employment type
- **Company Features**: Profile completeness, logo presence, description quality
- **Location Features**: Remote work indicators, location specificity

### Model Architecture
- **Ensemble Method**: Voting classifier combining:
  - Random Forest (200 trees, balanced weights)
  - Gradient Boosting (150 estimators, 0.1 learning rate)
  - Logistic Regression (balanced weights, L2 regularization)
- **Text Processing**: TF-IDF with 1-2 gram features (2000 max features)
- **Imbalance Handling**: SMOTE oversampling + balanced class weights
- **Evaluation**: 5-fold cross-validation, F1-score optimization

## ğŸ› Troubleshooting

### Common Issues

**1. "No module named 'sklearn'"**
\`\`\`bash
pip install scikit-learn pandas numpy matplotlib seaborn imbalanced-learn
\`\`\`

**2. "No trained model found"**
- Ensure you've run `python scripts/train_enhanced_model.py`
- Check that `training_data.csv` exists with `fraudulent` column

**3. "Failed to process file"**
- Verify CSV format and encoding (UTF-8 recommended)
- Ensure `title` column exists
- Check file size (max 10MB)

**4. Poor model performance**
- Ensure balanced training data (both fraud and genuine examples)
- Check data quality (complete descriptions, proper labels)
- Consider feature engineering for your specific domain

## ğŸ“ˆ Expected Performance

With quality training data:
- **F1-Score**: 0.85-0.90
- **Precision**: 0.86-0.92  
- **Recall**: 0.83-0.88
- **Processing Speed**: ~1000 jobs/second

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
\`\`\`

```typescriptreact file="components/training-status.tsx" isDeleted="true"
...deleted...
